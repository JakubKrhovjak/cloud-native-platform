# Terraform Infrastructure

This directory contains Terraform configuration for deploying GRUD to Google Cloud Platform (GKE).

## Architecture

```
GCP Project
├── VPC Network (grud-network)
│   ├── Subnet (10.0.0.0/24)
│   ├── Pod IP range (10.1.0.0/16)
│   └── Service IP range (10.2.0.0/20)
│
├── GKE Cluster (zonal: europe-west1-b)
│   ├── Infra Node Pool (3x e2-medium, spot)
│   │   └── Prometheus, Grafana, NATS, Loki, Tempo, Alloy
│   └── App Node Pool (1-4x e2-medium, spot, autoscaling)
│       └── student-service, project-service
│
├── Cloud SQL (PostgreSQL 15)
│   ├── Database: university (student-service)
│   └── Database: projects (project-service)
│
├── Artifact Registry (grud)
│   └── Container images for services
│
├── Google Secret Manager
│   ├── grud-jwt-secret
│   ├── grud-student-db-credentials
│   └── grud-project-db-credentials
│
└── External Secrets Operator (Helm)
    └── Syncs GSM secrets to Kubernetes
```

## Prerequisites

1. **Google Cloud SDK** installed and configured
2. **Terraform** >= 1.0
3. **kubectl** and **Helm** installed
4. **Ko** for building Go container images

```bash
# Install on macOS
brew install google-cloud-sdk terraform kubectl helm ko
```

## Quick Start

### 1. Authenticate with GCP

```bash
gcloud auth login
gcloud auth application-default login
gcloud config set project YOUR_PROJECT_ID
```

### 2. Create terraform.tfvars

```bash
cd terraform
cat > terraform.tfvars << EOF
project_id = "your-project-id"
region     = "europe-west1"
zone       = "europe-west1-b"

# Node configuration
infra_node_count = 3
app_node_count   = 1

# Database passwords (used for initial creation, then managed by Terraform random_password)
db_password_student = "initial-password"
db_password_project = "initial-password"
EOF
```

Note: The `db_password_*` variables are only used for initial setup. Actual passwords are generated by Terraform using `random_password` with URL-safe characters.

### 3. Deploy Infrastructure

```bash
# From project root
make tf/init
make tf/plan
make tf/apply
```

Or directly:

```bash
cd terraform
terraform init
terraform plan
terraform apply
```

### 4. Connect to Cluster

```bash
# Get cluster credentials
$(terraform output -raw get_credentials_command)

# Or use make
make gke/connect
```

### 5. Deploy Observability Stack

```bash
make infra/deploy-gke
```

### 6. Deploy Application

```bash
make gke/deploy
```

## File Structure

| File | Description |
|------|-------------|
| `apis.tf` | Enable required GCP APIs |
| `cloudsql.tf` | Cloud SQL PostgreSQL instance and databases |
| `gke.tf` | GKE cluster and node pools |
| `helm.tf` | External Secrets Operator Helm release |
| `iam.tf` | Service accounts and IAM bindings |
| `ingress.tf` | Static IP addresses for Ingress |
| `outputs.tf` | Terraform outputs |
| `registry.tf` | Artifact Registry for container images |
| `secrets.tf` | Google Secret Manager secrets |
| `variables.tf` | Input variables |
| `versions.tf` | Provider version constraints |
| `vpc.tf` | VPC network and subnets |

## Terraform Resources

### GKE Cluster

- **Type**: Zonal cluster (single zone for cost efficiency)
- **Location**: europe-west1-b
- **Features**:
  - Private nodes (no public IPs on nodes)
  - Workload Identity (secure GCP API access)
  - Dataplane V2 (eBPF/Cilium networking)
  - Master authorized networks

### Node Pools

| Pool | Purpose | Nodes | Machine | Spot |
|------|---------|-------|---------|------|
| infra-pool | Monitoring, NATS | 3 | e2-medium | Yes |
| app-pool | Applications | 1-4 | e2-medium | Yes |

App pool has autoscaling and taint `workload=app:NoSchedule`.

### Cloud SQL

- **Version**: PostgreSQL 15
- **Instance**: db-custom-1-3840 (1 vCPU, 3.75GB RAM)
- **Disk**: 10GB HDD
- **Connection**: Private IP via VPC peering

**Databases**:
- `university` - student-service (user: `student_user`)
- `projects` - project-service (user: `project_user`)

### Secrets

Secrets are stored in Google Secret Manager and synced to Kubernetes using External Secrets Operator:

| GSM Secret | Kubernetes Secret | Used By |
|------------|-------------------|---------|
| `grud-jwt-secret` | `jwt-secret` | student-service |
| `grud-student-db-credentials` | `student-db-secret` | student-service |
| `grud-project-db-credentials` | `project-db-secret` | project-service |

Database credentials are stored as JSON:
```json
{
  "username": "student_user",
  "password": "generated-url-safe-password",
  "database": "university"
}
```

## Makefile Commands

```bash
# Terraform
make tf/init      # Initialize Terraform
make tf/plan      # Plan changes
make tf/apply     # Apply configuration
make tf/destroy   # Destroy all resources
make tf/output    # Show outputs

# GKE
make gke/connect  # Get cluster credentials
make gke/deploy   # Build and deploy application
make gke/status   # Show cluster status
make gke/clean    # Uninstall Helm release

# Full deployment
make gke/full-deploy  # tf/init + tf/apply + infra + app
```

## Outputs

After deployment, view outputs with:

```bash
cd terraform
terraform output
```

Key outputs:
- `cluster_name` - GKE cluster name
- `registry_url` - Artifact Registry URL
- `cloudsql_private_ip` - Cloud SQL private IP
- `ingress_ip` - Static IP for Ingress
- `get_credentials_command` - kubectl auth command

## Cost Optimization

This configuration is optimized for development/demo with minimal cost:

1. **Spot VMs** - Up to 91% cheaper than on-demand
2. **Zonal cluster** - No cross-zone traffic
3. **e2-medium** - Smallest practical size
4. **HDD storage** - Cheaper than SSD for Cloud SQL
5. **Single Cloud SQL instance** - No HA (ZONAL availability)
6. **No backups** - Disabled for Cloud SQL

For production, consider:
- Regional cluster
- On-demand nodes (or mix)
- SSD storage
- HA Cloud SQL
- Enable backups

## Troubleshooting

### Permission Denied

```bash
# Ensure you're authenticated
gcloud auth application-default login

# Check project
gcloud config get-value project
```

### Cloud SQL Connection Issues

```bash
# Verify private IP
terraform output cloudsql_private_ip

# Check VPC peering
gcloud services vpc-peerings list --network=grud-network
```

### External Secrets Not Syncing

```bash
# Check External Secrets Operator
kubectl logs -n external-secrets-system deployment/external-secrets

# Check ExternalSecret status
kubectl describe externalsecret -n grud

# Check SecretStore
kubectl describe secretstore -n grud
```

### Workload Identity Issues

```bash
# Verify service account annotation
kubectl get serviceaccount -n grud -o yaml | grep gcp-service-account

# Check IAM binding
gcloud iam service-accounts get-iam-policy \
  grud-secrets-sa@PROJECT_ID.iam.gserviceaccount.com
```

## Destroying Infrastructure

```bash
# Remove Helm release first
make gke/clean
make infra/cleanup

# Destroy Terraform resources
make tf/destroy
```

**Warning**: This will delete all data including Cloud SQL databases and secrets.

## Accessing Services

After deployment:

```bash
# Get Ingress IP
kubectl get ingress -n grud

# Access API
curl http://$(terraform output -raw ingress_ip)/api/students

# Port-forward Grafana
make gke/grafana
# Then open http://localhost:3000
```

## Database Access

Connect to Cloud SQL via Cloud SQL Proxy or kubectl:

```bash
# Find a pod
kubectl get pods -n grud

# Exec into pod and use psql
kubectl exec -it -n grud deployment/student-service -- sh
# Inside pod: psql is not available, use Cloud SQL Proxy

# Using Cloud SQL Proxy locally
cloud-sql-proxy PROJECT_ID:europe-west1:grud-postgres &
psql -h 127.0.0.1 -U student_user -d university
```

Or grant permissions to existing tables:

```bash
# Connect as postgres user (requires password reset in console)
gcloud sql connect grud-postgres --user=postgres --database=university

# Grant permissions
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO student_user;
GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO student_user;
```
